{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-LSTM for fall detection\n",
    "Group : Yemi, Dongzi, Harkey, Sidd, Sol√®ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KinectData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDH = np.zeros((1,112))\n",
    "labels = np.zeros((1,1))\n",
    "\n",
    "RK = pd.DataFrame()\n",
    "Labels = pd.DataFrame()\n",
    "\n",
    "actions = ['walk', 'run', 'jump', 'legup', 'pickup', 'walk2', 'highfall', 'sitandup', 'movewithchair', 'fallchair', 'upsitbed', 'uplyingbed', 'fallbed']\n",
    "for i in range(1,7) :\n",
    "    for a in actions :\n",
    "        try :\n",
    "            labels_i = pd.read_csv(\"DATA/Test_data/KinectData/S1/S1P19K\"+str(i)+\"_\" + a + \"_cut_label.csv\", index_col = 0)\n",
    "            NDH_i = pd.read_csv(\"DATA/Test_data/KinectData/S1/S1P19K\" + str(i) + \"_\" + a + \"_RegKey.csv\", header=None)\n",
    "            if (len(labels_i) == len(NDH_i)) :\n",
    "                print(i,a)\n",
    "                \n",
    "                df_lab = pd.DataFrame(labels_i)\n",
    "                df_ndh = pd.DataFrame(NDH_i)\n",
    "\n",
    "                video_name = \"S1P19K\"+str(i)+\"_\" + a \n",
    "                video_lab = [video_name] * len(df_lab)\n",
    "                video_ndh = [video_name] * len(df_ndh)\n",
    "                df_lab['Video'] = video_lab\n",
    "                df_ndh['Video'] = video_ndh\n",
    "                \n",
    "                frame_ndh = [RK, df_ndh]\n",
    "                frame_lab = [Labels, df_lab]\n",
    "                RK = pd.concat(frame_ndh,axis = 0)\n",
    "                Labels = pd.concat(frame_lab,axis = 0)            \n",
    "            \n",
    "        except :\n",
    "            pass\n",
    "\n",
    "\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "RK = RK.set_index('Video')\n",
    "del RK[0]\n",
    "Labels = Labels.set_index('Video')\n",
    "print(RK)\n",
    "print(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 1\n",
    "batch_size = 1\n",
    "\n",
    "x_train_final = np.zeros((1,lookback,112))\n",
    "y_train_final = np.zeros((1,1))\n",
    "\n",
    "\n",
    "for i in range(1,7):\n",
    "    for a in actions :\n",
    "        try:\n",
    "            y_train = Labels.loc[[\"S1P19K\"+str(i)+\"_\" + a]]['label'].values\n",
    "            y_train = y_train.reshape(-1,1)\n",
    "\n",
    "            x_train = RK.loc[[\"S1P19K\"+str(i)+\"_\" + a]].values\n",
    "\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(x_train)\n",
    "            x_train_scaled = scaler.transform(x_train)\n",
    "            #print(x_train_scaled)\n",
    "\n",
    "            #time series generator \n",
    "            ts_generator = keras.preprocessing.sequence.TimeseriesGenerator(x_train_scaled,y_train,length=lookback,batch_size=batch_size)\n",
    "            x_ts = ts_generator[0][0]\n",
    "            y_ts = ts_generator[0][1]\n",
    "\n",
    "            #print(x_ts)\n",
    "            #print(y_ts)\n",
    "\n",
    "            for j in range(1,len(ts_generator)):\n",
    "                #concatenate the series together\n",
    "                x_ts = np.concatenate((x_ts,ts_generator[j][0]))\n",
    "                y_ts = np.concatenate((y_ts,ts_generator[j][1]))\n",
    "\n",
    "            #concatenate the series of every airplane to the final matrix\n",
    "            x_train_final = np.concatenate((x_train_final,x_ts),axis = 0)\n",
    "            y_train_final = np.concatenate((y_train_final,y_ts),axis = 0)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    " # removing the first row because its composed of zeros when we created the matrices\n",
    "x_train_final = x_train_final[1:]\n",
    "y_train_final = y_train_final[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_final.shape)\n",
    "print(y_train_final.shape)\n",
    "print(x_train_final)\n",
    "print(y_train_final)\n",
    "#54 videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 1D CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_final = x_train_final.reshape(len(x_train_final),112)\n",
    "x_train_final = x_train_final.reshape(len(x_train_final),8,14)\n",
    "x_train_final = x_train_final.reshape(len(x_train_final),8,14,1)\n",
    "\n",
    "model = keras.Sequential()\n",
    "# define CNN model\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Conv1D(32,2,activation='relu', input_shape = (8,14))))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.MaxPooling1D(2)))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Flatten()))\n",
    "# define LSTM model\n",
    "model.add(keras.layers.LSTM(160,activation='relu'))\n",
    "model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 2D CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_batch = 10\n",
    "\n",
    "x_train_final = x_train_final[:np.int64(len(x_train_final)/frame_batch)*frame_batch, :, :]\n",
    "y_train_final = y_train_final[:np.int64(len(y_train_final)/frame_batch)*frame_batch, :]\n",
    "\n",
    "x_train_final = x_train_final.reshape(np.int64(len(x_train_final)/frame_batch),frame_batch,8,14,1)\n",
    "y_train_final = y_train_final.reshape(np.int64(len(y_train_final)/frame_batch),frame_batch,1)\n",
    "\n",
    "print(x_train_final.shape)\n",
    "print(y_train_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faster\n",
    "model = keras.Sequential()\n",
    "# define CNN model\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Conv2D(32,(3,3),activation='relu', input_shape = (frame_batch,8,14))))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.MaxPooling2D((3,3))))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Flatten()))\n",
    "# define LSTM model\n",
    "model.add(keras.layers.LSTM(160,activation='relu'))\n",
    "model.add(keras.layers.Dense(frame_batch,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 3D CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Longer\n",
    "frame_batch = 10\n",
    "\n",
    "x_train_final = x_train_final[:np.int64(len(x_train_final)/frame_batch)*frame_batch, :, :]\n",
    "y_train_final = y_train_final[:np.int64(len(y_train_final)/frame_batch)*frame_batch, :]\n",
    "\n",
    "x_train_final = x_train_final.reshape(np.int64(len(x_train_final)/frame_batch),frame_batch,8,14,1,1)\n",
    "y_train_final = y_train_final.reshape(np.int64(len(y_train_final)/frame_batch),frame_batch,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_final = x_train_final.reshape(len(x_train_final),1,frame_batch,8,14,1)\n",
    "\n",
    "print(x_train_final.shape)\n",
    "print(y_train_final.shape)\n",
    "\n",
    "model = keras.Sequential()\n",
    "# define CNN model\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Conv3D(32,(2,2,2),activation='relu', input_shape = (frame_batch,8,14,1))))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.MaxPooling3D((2,2,2))))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Flatten()))\n",
    "# define LSTM model\n",
    "model.add(keras.layers.LSTM(160,activation='relu'))\n",
    "model.add(keras.layers.Dense(frame_batch,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "model.fit(x_train_final,y_train_final,epochs=25,batch_size = 20, validation_split = 0.2) #callbacks=[early_stopping_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.history.history[\"loss\"]).plot(linestyle = \"-\",linewidth=2)\n",
    "plt.grid(color='#95a5a6', linestyle='--', linewidth=1, alpha=0.4)\n",
    "plt.xlabel(\"Epochs\",fontdict = {\"fontsize\": 12}) #number of epochs\n",
    "plt.ylabel(\"Losses\",fontdict = {\"fontsize\": 12}) #label the loss\n",
    "plt.title(\"Training Loss 2D Conv NN\",fontdict = {\"fontsize\": 12})\n",
    "plt.legend().set_visible(False)\n",
    "plt.savefig('Training Loss 2D Conv NN.jpg')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegKey_label_predict = np.round(model.predict(RegKey_test))\n",
    "\n",
    "M_conf = np.zeros((2,2))\n",
    "for i in range(len(RegKey_label_predict)) :\n",
    "    if (RegKey_label_predict[i] == 1 and RegKey_label_true[i] == 1) :\n",
    "        M_conf[0,0] += 1\n",
    "    if (RegKey_label_predict[i] == 1 and RegKey_label_true[i] == 0) :\n",
    "        M_conf[0,1] += 1\n",
    "    if (RegKey_label_predict[i] == 0 and RegKey_label_true[i] == 1) :\n",
    "        M_conf[1,0] += 1\n",
    "    if (RegKey_label_predict[i] == 0 and RegKey_label_true[i] == 0) :\n",
    "        M_conf[1,1] += 1\n",
    "\n",
    "print(M_conf)\n",
    "print(\"Accuracy = \", np.round((M_conf[0,0] + M_conf[1,1])*100/len(RegKey_label_true),1),' %')\n",
    "\n",
    "#print(RegKey_label_true)\n",
    "#print(RegKey_label_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall dataset in MoveNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGKEY = pd.DataFrame()\n",
    "LABELS = pd.DataFrame()\n",
    "\n",
    "Falls = [\"00003\",\"00004\",\"00005\",\"00006\",\"00007\",\"00008\",\"00009\",\"00010\",\"00011\",\"00012\",\"00013\",\"00014\",\"00015\",\"00016\"]\n",
    "\n",
    "for fall_number in Falls :\n",
    "    REGKEY_i = pd.read_csv('DATA/Falls_MoveNet/Fall_'+fall_number+'_RegKey.csv', header = None).values[:,1:]\n",
    "    LABELS_i = pd.read_csv('DATA/Falls_MoveNet/Fall_'+fall_number+'_label.csv',index_col = 0)\n",
    "    \n",
    "    df = pd.DataFrame(REGKEY_i)\n",
    "    video_name = \"Fall_\" + fall_number\n",
    "    video = [video_name] * len(df)\n",
    "    df['Video'] = video\n",
    "                \n",
    "    frame = [REGKEY, df]\n",
    "    REGKEY = pd.concat(frame,axis = 0)\n",
    "    \n",
    "    frame = [LABELS, LABELS_i]\n",
    "    LABELS = pd.concat(frame,axis = 0)\n",
    "\n",
    "\n",
    "REGKEY = REGKEY.set_index('Video')\n",
    "    \n",
    "REGKEY.to_csv('DATA/Falls_MoveNet/Falls_MoveNet_RegKey_DataFrame.csv')\n",
    "LABELS.to_csv('DATA/Falls_MoveNet/Falls_MoveNet_Labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Videos with frame batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGKEY = pd.read_csv('DATA/Falls_MoveNet/Falls_MoveNet_RegKey_DataFrame.csv',index_col = 0)\n",
    "LABELS = pd.read_csv('DATA/Falls_MoveNet/Falls_MoveNet_Labels.csv',index_col = 0)\n",
    "\n",
    "Falls = [\"00003\",\"00004\",\"00005\",\"00006\",\"00008\",\"00009\",\"00010\",\"00011\",\"00012\",\"00013\",\"00014\",\"00015\",\"00016\"]\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "TN = 0\n",
    "\n",
    "BIG_Y_TEST = np.array([0]).reshape(1,1)\n",
    "BIG_Y_PREDICT = np.array([0])\n",
    "\n",
    "for fall_number in Falls :\n",
    "\n",
    "    x_test = REGKEY.loc['Fall_'+fall_number].values\n",
    "    #conv1d\n",
    "    x_test = x_test.reshape(len(x_test),8,14,1)\n",
    "    #conv2d\n",
    "    #x_test = x_test[:np.int64(len(x_test)/frame_batch)*frame_batch].reshape(np.int64(len(x_test)/frame_batch),frame_batch,8,14,1)\n",
    "    #conv3d\n",
    "    #x_test = x_test[:np.int64(len(x_test)/frame_batch)*frame_batch].reshape(np.int64(len(x_test)/frame_batch),1,frame_batch,8,14,1)\n",
    "    \n",
    "    y_test_true = LABELS.loc['Fall_'+fall_number][['label']].values\n",
    "    #conv2/3d\n",
    "    #y_test_true = y_test_true[:np.int64(len(y_test_true)/frame_batch)*frame_batch].reshape(np.int64(len(y_test_true)/frame_batch),frame_batch,1)\n",
    "        \n",
    "    #print(model.predict(x_test))\n",
    "    #print(np.round(model.predict(x_test)))\n",
    "    \n",
    "    y_test_predict = np.round(model.predict(x_test))\n",
    "    #conv2/3d\n",
    "    #y_test_predict = y_test_predict.reshape(len(y_test_predict)*frame_batch)\n",
    "    #y_test_true = y_test_true.reshape(len(y_test_true)*frame_batch)\n",
    "    \n",
    "    BIG_Y_TEST = np.concatenate((BIG_Y_TEST,y_test_true),axis = 0)\n",
    "    \n",
    "    print(y_test_predict)\n",
    "    \n",
    "    average_prediction = np.zeros(len(y_test_true))\n",
    "    for i in range(len(y_test_true)) :\n",
    "        average_prediction[i] = np.round(np.mean(y_test_predict[i-10 if i-10 >= 0 else i:i+1]))\n",
    "    y_test_predict = average_prediction\n",
    "    BIG_Y_PREDICT = np.concatenate((BIG_Y_PREDICT,y_test_predict),axis = 0)\n",
    "    #print(average_prediction)\n",
    "    \n",
    "    M_conf = np.zeros((2,2))\n",
    "    for i in range(len(y_test_predict)) :\n",
    "        if (y_test_predict[i] == 1 and y_test_true[i] == 1) :\n",
    "            M_conf[0,0] += 1\n",
    "        if (y_test_predict[i] == 1 and y_test_true[i] == 0) :\n",
    "            M_conf[0,1] += 1\n",
    "        if (y_test_predict[i] == 0 and y_test_true[i] == 1) :\n",
    "            M_conf[1,0] += 1\n",
    "        if (y_test_predict[i] == 0 and y_test_true[i] == 0) :\n",
    "            M_conf[1,1] += 1\n",
    "\n",
    "    print(M_conf)\n",
    "    \n",
    "    TP += M_conf[0,0]\n",
    "    FP += M_conf[0,1]\n",
    "    FN += M_conf[1,0]\n",
    "    TN += M_conf[1,1]\n",
    "\n",
    "    accuracy = np.round((M_conf[0,0] + M_conf[1,1])*100/len(y_test_true),1)\n",
    "    print(\"Accuracy fall \",fall_number,\" = \", accuracy,' %')\n",
    "    #np.savetxt('DATA/Falls_MoveNet/Fall_'+fall_number+'_prediction_conv2d_average.csv', y_test_predict, delimiter=\",\")\n",
    "    #np.savetxt('DATA/Falls_MoveNet/Fall_'+fall_number+'_accuracy_conv2d_average.csv', np.array([accuracy]), delimiter=\",\")\n",
    " \n",
    "\n",
    " \n",
    "print(\"TOTAL MEAN Accuracy : \", np.round((TP + TN)/(TP + FP + FN + TN)*100,1), '%')\n",
    "print(\"TOTAL MEAN Error : \", np.round((FP + FN)/(TP + FP + FN + TN)*100,1), '%')\n",
    "print(\"TOTAL MEAN Sensitivity : \", np.round(TP/(TP + FN)*100,1), '%')\n",
    "print(\"TOTAL MEAN Specificity : \", np.round(TN/(TN + FP)*100,1), '%')\n",
    "\n",
    "print(BIG_Y_TEST.shape)\n",
    "print(BIG_Y_PREDICT.shape)\n",
    "\n",
    "print(TP,FP,FN,TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test single video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"DATA/Test_data/CRANFIELD_test-data/Dongzi Camera/IMG_3777_Trim.mp4\"\n",
    "\n",
    "REGKEY = pd.read_csv('DATA/Test_data/CRANFIELD_test-data/Dongzi Camera/IMG_3777_Trim_RegKey.csv',header=None).to_numpy()[:,1:]\n",
    "LABELS = pd.read_csv('DATA/Test_data/CRANFIELD_test-data/Dongzi Camera/IMG_3777_Trim_label.csv',index_col = 0)['label'].to_numpy().reshape(-1,1)\n",
    "\n",
    "\n",
    "x_test = REGKEY\n",
    "x_test = x_test.reshape(len(x_test),8,14)\n",
    "y_test_true = LABELS\n",
    "\n",
    "x_test = x_test[:np.int64(len(x_test)/frame_batch)*frame_batch].reshape(np.int64(len(x_test)/frame_batch),1,frame_batch,8,14,1)\n",
    "y_test_true = y_test_true[:np.int64(len(y_test_true)/frame_batch)*frame_batch].reshape(np.int64(len(y_test_true)/frame_batch),frame_batch,1)\n",
    "\n",
    "\n",
    "\n",
    "y_test_predict = np.round(model.predict(x_test))\n",
    "y_test_predict = y_test_predict.reshape(len(y_test_predict)*frame_batch)\n",
    "y_test_true = y_test_true.reshape(len(y_test_true)*frame_batch)\n",
    "\n",
    "print(y_test_predict.reshape(-1,1))\n",
    "average_prediction = np.zeros(len(y_test_predict))\n",
    "for i in range(len(y_test_predict)) :\n",
    "    average_prediction[i] = np.round(np.mean(y_test_predict[i-15 if i-15 >= 0 else i:i+1]))\n",
    "y_test_predict = average_prediction\n",
    "\n",
    "print(average_prediction)\n",
    "\n",
    "M_conf = np.zeros((2,2))\n",
    "for i in range(len(y_test_predict)) :\n",
    "    if (y_test_predict[i] == 1 and y_test_true[i] == 1) :\n",
    "        M_conf[0,0] += 1\n",
    "    if (y_test_predict[i] == 1 and y_test_true[i] == 0) :\n",
    "        M_conf[0,1] += 1\n",
    "    if (y_test_predict[i] == 0 and y_test_true[i] == 1) :\n",
    "        M_conf[1,0] += 1\n",
    "    if (y_test_predict[i] == 0 and y_test_true[i] == 0) :\n",
    "        M_conf[1,1] += 1\n",
    "\n",
    "print(M_conf)\n",
    "\n",
    "print(\"Accuracy fall  = \", np.round((M_conf[0,0] + M_conf[1,1])*100/len(y_test_true),1),' %')\n",
    "#np.savetxt('DATA/Test_data/CRANFIELD_test-data/Dongzi Camera/IMG_3777_Trim_prediction_conv2d.csv', average_prediction, delimiter=\",\")\n",
    "#np.savetxt('DATA/Test_data/CRANFIELD_test-data/Dongzi Camera/IMG_3777_Trim_accuracy_conv2d.csv', np.array([np.round((M_conf[0,0] + M_conf[1,1])*100/len(y_test_true),1)]), delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv1d\n",
    "BIG_Y_TEST = BIG_Y_TEST.reshape(1,len(BIG_Y_TEST))[0]\n",
    "print(BIG_Y_PREDICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(BIG_Y_TEST[1:],BIG_Y_PREDICT[1:])\n",
    "fig,ax1 = plt.subplots(figsize=(5,3))\n",
    "ax1 = sns.heatmap(cm,annot=True,fmt='d',ax=ax1,cmap =\"coolwarm\", annot_kws={'fontsize':20})\n",
    "ax1.set_xlabel(\"Prediction\",fontdict = {\"fontsize\": 15})\n",
    "ax1.set_ylabel(\"True\",fontdict = {\"fontsize\": 15})\n",
    "ax1.set_title(\"Confusion Matrix Conv3D\",fontdict = {\"fontsize\": 15})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
